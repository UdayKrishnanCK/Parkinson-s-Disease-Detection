{"cells": [{"metadata": {}, "cell_type": "code", "source": "pwd", "execution_count": 1, "outputs": [{"output_type": "execute_result", "execution_count": 1, "data": {"text/plain": "'/home/wsuser/work'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "import warnings\nwarnings.filterwarnings(\"ignore\")", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "!pip install imutils", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "Collecting imutils\n  Downloading imutils-0.5.4.tar.gz (17 kB)\nBuilding wheels for collected packages: imutils\n  Building wheel for imutils (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25860 sha256=9b27083f9cc4fd096c0ed96e02d664a4fd9cbef45c07309a802fd276271febc4\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/4b/a5/2d/4a070a801d3a3d93f033d3ee9728f470f514826e89952df3ea\nSuccessfully built imutils\nInstalling collected packages: imutils\nSuccessfully installed imutils-0.5.4\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Image Pre-processing"}, {"metadata": {}, "cell_type": "markdown", "source": "### Importing the necessary libraries"}, {"metadata": {"id": "sonZSFj3Cl-r", "scrolled": true}, "cell_type": "code", "source": "import cv2\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom skimage import feature\nfrom imutils import paths\nimport os\nimport pickle", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Functions to load and quantify the images "}, {"metadata": {}, "cell_type": "code", "source": "import os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='rlyEPAR18kPTMGZRByQGAWk_2w81tdr_D7ky9zEjT6ja',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n\nbucket = 'parkinson39sdiseasedetection-donotdelete-pr-9rhldkrukkwg0y'\nobject_key = 'dataset.zip'\n\nstreaming_body_1 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\n", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from io import BytesIO\nimport zipfile\nunzip = zipfile.ZipFile(BytesIO(streaming_body_1.read()),'r')\nfile_paths = unzip.namelist()\nfor path in file_paths:\n    unzip.extract(path)", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "pwd", "execution_count": 7, "outputs": [{"output_type": "execute_result", "execution_count": 7, "data": {"text/plain": "'/home/wsuser/work'"}, "metadata": {}}]}, {"metadata": {"id": "Nq6-QVvBETiY"}, "cell_type": "code", "source": "def quantify_image(image):\n    features = feature.hog(image, \n                           orientations=9, \n                           pixels_per_cell=(5,5), \n                           cells_per_block=(2,2), \n                           transform_sqrt=True, \n                           block_norm=\"L1\")\n    return features", "execution_count": 8, "outputs": []}, {"metadata": {"id": "uqnoTiIiF-pN"}, "cell_type": "code", "source": "def load_split(path):\n    path_images = list(paths.list_images(path))\n    data=[]\n    labels=[]\n\n    for path_image in path_images:\n        label = path_image.split(os.path.sep)[-2]\n        image = cv2.imread(path_image)\n        image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n        image = cv2.resize(image, (200,200))\n        image = cv2.threshold(image,0,225,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n\n        features = quantify_image(image)\n        data.append(features)\n        labels.append(label)\n\n    return (np.array(data), np.array(labels))\n", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Using spiral images"}, {"metadata": {}, "cell_type": "markdown", "source": "### Defining the path for training data and testing data"}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "5hv2fgLED8vO", "outputId": "1c1a4ada-99c6-43de-ee34-c6f8b7c81887"}, "cell_type": "code", "source": "path_training_data = r\"/home/wsuser/work/dataset/spiral/training\"\npath_testing_data = r\"/home/wsuser/work/dataset/spiral/testing\"", "execution_count": 10, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Loading the training and testing data"}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "rxwdUgSrHVnl", "outputId": "8a569025-1f4d-41eb-8199-162a823517f0"}, "cell_type": "code", "source": "(x_train, y_train) = load_split(path_training_data)\n(x_test, y_test) = load_split(path_testing_data)", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Label Encoding"}, {"metadata": {}, "cell_type": "code", "source": "label_encoder = LabelEncoder()\ny_train = label_encoder.fit_transform(y_train)\ny_test = label_encoder.transform(y_test)\nprint(x_train.shape, y_train.shape)\n# 0:healthy,1:Parkinson", "execution_count": 12, "outputs": [{"output_type": "stream", "text": "(72, 54756) (72,)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Building the model"}, {"metadata": {}, "cell_type": "markdown", "source": "### Training the model"}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "model = RandomForestClassifier(n_estimators=100)\nmodel.fit(x_train, y_train)", "execution_count": 13, "outputs": [{"output_type": "execute_result", "execution_count": 13, "data": {"text/plain": "RandomForestClassifier()"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Testing the model"}, {"metadata": {}, "cell_type": "code", "source": "testingPaths = list(paths.list_images(path_testing_data))\nidxs = np.arange(0, len(testingPaths))\nidxs = np.random.choice(idxs, size=(25,), replace=False) \nimages = []", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "for i in idxs:\n    # loading the testing image, clone it, and resize it \n    image = cv2.imread(testingPaths[i]) \n    output = image. copy() \n    output = cv2. resize(output, (128, 128))\n    \n    # pre-processing the image \n    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n    image = cv2.resize(image, (200, 200))\n    image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU) [1]\n    \n    # quantify the image and make predictions based on the extracted \n    # features using the last trained Random Forest \n    features = quantify_image(image) \n    preds = model.predict([features])\n\n    label = label_encoder.inverse_transform(preds)[0]\n\n    # draw the colored class label on the output image and add it to the set of output images \n    if label == \"healthy\":\n        color = (0, 255, 0)  \n    else:\n        color = (0, 0, 255) \n    cv2.putText(output, label, (3, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2) \n    images.append(output)", "execution_count": 15, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Evaluating the model"}, {"metadata": {}, "cell_type": "code", "source": "predictions = model.predict(x_test)    # predictions on the testing data \n\ncm = confusion_matrix(y_test, predictions).flatten ()    # computing the confusion matrix\nprint(cm) \n(tn, fp, fn, tp) = cm \n\naccuracy = (tp + tn) / float(cm.sum())     # computing the accuracy\nprint(accuracy)", "execution_count": 16, "outputs": [{"output_type": "stream", "text": "[12  3  5 10]\n0.7333333333333333\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Saving the model"}, {"metadata": {}, "cell_type": "code", "source": "pickle.dump(model,open('parkinson.pkl', 'wb'))", "execution_count": 17, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "!tar -zcvf parkinsonsmodel.tgz parkinson.pkl", "execution_count": 18, "outputs": [{"output_type": "stream", "text": "parkinson.pkl\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "ls", "execution_count": 19, "outputs": [{"output_type": "stream", "text": "\u001b[0m\u001b[01;34mdataset\u001b[0m/  parkinson.pkl  parkinsonsmodel.tgz\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "!pip install watson-machine-learning-client --upgrade", "execution_count": 20, "outputs": [{"output_type": "stream", "text": "Collecting watson-machine-learning-client\n  Downloading watson_machine_learning_client-1.0.391-py3-none-any.whl (538 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 538 kB 23.3 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: urllib3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.26.7)\nRequirement already satisfied: pandas in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.3.4)\nRequirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.11.0)\nRequirement already satisfied: tqdm in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (4.62.3)\nRequirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.26.0)\nRequirement already satisfied: tabulate in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.8.9)\nRequirement already satisfied: lomond in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.3.3)\nRequirement already satisfied: certifi in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2022.9.24)\nRequirement already satisfied: boto3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.18.21)\nRequirement already satisfied: botocore<1.22.0,>=1.21.21 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (1.21.41)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.10.0)\nRequirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.5.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (2.8.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (1.15.0)\nRequirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\nRequirement already satisfied: ibm-cos-sdk-core==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (3.3)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (2.0.4)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (2021.3)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (1.20.3)\nInstalling collected packages: watson-machine-learning-client\nSuccessfully installed watson-machine-learning-client-1.0.391\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watson_machine_learning import APIClient\nwml_credentials = {\n                    \"url\" : \"https://us-south.ml.cloud.ibm.com\",\n                    \"apikey\" : \"K36t7CdPrC_R4VWU_knCWisv6ePwSofTJbYqDvwtHL54\"\n                    }\nclient = APIClient(wml_credentials)", "execution_count": 21, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def guid_from_space_name(client,space_name):\n    space = client.spaces.get_details()\n    print(space)\n    return (next(item for item in space['resources'] if item['entity']['name']==space_name)['metadata']['id'])", "execution_count": 22, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "space_uid = guid_from_space_name(client,'ParkinsonsDiseaseDetection')\nprint('Space UID = ' + space_uid)", "execution_count": 23, "outputs": [{"output_type": "stream", "text": "{'resources': [{'entity': {'compute': [{'crn': 'crn:v1:bluemix:public:pm-20:us-south:a/b84b413d6b9e4175b7855d4dd2ee33d9:9ba5da9b-52e4-4572-8e8d-fff28a6b8cc6::', 'guid': '9ba5da9b-52e4-4572-8e8d-fff28a6b8cc6', 'name': 'Watson Machine Learning-ki', 'type': 'machine_learning'}], 'description': '', 'name': 'ParkinsonsDiseaseDetection', 'scope': {'bss_account_id': 'b84b413d6b9e4175b7855d4dd2ee33d9'}, 'stage': {'production': False}, 'status': {'state': 'active'}, 'storage': {'properties': {'bucket_name': '5a89077f-3edd-4509-b6cb-d2ee2ab49e86', 'bucket_region': 'us-south', 'credentials': {'admin': {'access_key_id': '40e04ea2f6794d2b80c672bfeffc7d49', 'api_key': '3hGFaYijB8KkwMkcI_qtULkbD3eteT16p8zj8XHxLGtC', 'secret_access_key': '05736898bfeea8166d65dfe96f880c8b86568f8657a2de79', 'service_id': 'ServiceId-46cc9955-6c14-4654-8e28-6bddac6edf85'}, 'editor': {'access_key_id': 'b07c7bcf702144d4a375823ae0af96ec', 'api_key': 'D1Nyz0418QME4N9Uj5TM_8RKjnEdxDmViSP7OjpGgdrQ', 'resource_key_crn': 'crn:v1:bluemix:public:cloud-object-storage:global:a/b84b413d6b9e4175b7855d4dd2ee33d9:52e3193a-fa9f-456b-b6b9-622bab2e14da::', 'secret_access_key': 'fb80d5e86211a137d0d3e6a2326097aaa3a53ef7a045171a', 'service_id': 'ServiceId-84dbe5bf-0b52-499e-abef-200b6c559008'}, 'viewer': {'access_key_id': '3926e20b134d45d390f591b850a7c3d7', 'api_key': 'trvpZajav9JLw4OICLsM2d2YTpbi5ktaS2WwdTO0RPyI', 'resource_key_crn': 'crn:v1:bluemix:public:cloud-object-storage:global:a/b84b413d6b9e4175b7855d4dd2ee33d9:52e3193a-fa9f-456b-b6b9-622bab2e14da::', 'secret_access_key': '895dd6601095ae7ce0dc364772c08467aa8528e27cfee218', 'service_id': 'ServiceId-ed13ae44-7930-4905-bf54-20afb6666b27'}}, 'endpoint_url': 'https://s3.us-south.cloud-object-storage.appdomain.cloud', 'guid': '52e3193a-fa9f-456b-b6b9-622bab2e14da', 'resource_crn': 'crn:v1:bluemix:public:cloud-object-storage:global:a/b84b413d6b9e4175b7855d4dd2ee33d9:52e3193a-fa9f-456b-b6b9-622bab2e14da::'}, 'type': 'bmcos_object_storage'}}, 'metadata': {'created_at': '2022-11-06T10:45:00.878Z', 'creator_id': 'IBMid-661003W5ZK', 'id': 'd0435865-9f33-4cc1-a138-be8baff7e159', 'updated_at': '2022-11-06T11:02:13.878Z', 'url': '/v2/spaces/d0435865-9f33-4cc1-a138-be8baff7e159'}}]}\nSpace UID = d0435865-9f33-4cc1-a138-be8baff7e159\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "client.set.default_space(space_uid)", "execution_count": 24, "outputs": [{"output_type": "execute_result", "execution_count": 24, "data": {"text/plain": "'SUCCESS'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "client.software_specifications.list()", "execution_count": 25, "outputs": [{"output_type": "stream", "text": "-----------------------------  ------------------------------------  ----\nNAME                           ASSET_ID                              TYPE\ndefault_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\nkernel-spark3.2-scala2.12      020d69ce-7ac1-5e68-ac1a-31189867356a  base\npytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base\nscikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\nspark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\npytorch-onnx_rt22.1-py3.9      0b848dd4-e681-5599-be41-b5f6fccc6471  base\nai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\nshiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base\ntensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base\npytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base\ntensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base\nruntime-22.1-py3.9             12b83a17-24d8-5082-900f-0ab31fbfd3cb  base\nscikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\ndefault_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\npytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\nkernel-spark3.3-r3.6           1c9e5454-f216-59dd-a20e-474a5cdf5988  base\npytorch-onnx_rt22.1-py3.9-edt  1d362186-7ad5-5b59-8b6c-9d0880bde37f  base\ntensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\nspark-mllib_3.2                20047f72-0a98-58c7-9ff5-a77b012eb8f5  base\ntensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base\nruntime-22.1-py3.9-cuda        26215f05-08c3-5a41-a1b0-da66306ce658  base\ndo_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base\nautoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\ntensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base\nkernel-spark3.3-py3.9          2b7961e2-e3b1-5a8c-a491-482c8368839a  base\npytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base\nspark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base\npytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base\nspark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base\nspark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base\nxgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base\npytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\ndefault_r36py38                41c247d3-45f8-5a71-b065-8580229facf0  base\nautoai-ts_rt22.1-py3.9         4269d26e-07ba-5d40-8f66-2d495b0c71f7  base\nautoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\npmml-3.0_4.3                   493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base\nspark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base\nxgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base\npytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\nautoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base\nspark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base\nspark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\nautoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base\nspss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\ncuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\nautoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base\npytorch-onnx_1.7-py3.8         634d3cdc-b562-5bf9-a2d4-ea90a478456b  base\nspark-mllib_2.3-r_3.6          6586b9e3-ccd6-4f92-900f-0f8cb2bd6f0c  base\ntensorflow_2.4-py3.7           65e171d7-72d1-55d9-8ebb-f813d620c9bb  base\nspss-modeler_18.2              687eddc9-028a-4117-b9dd-e57b36f1efa5  base\n-----------------------------  ------------------------------------  ----\nNote: Only first 50 records were displayed. To display more use 'limit' parameter.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "software_spec_uid=client.software_specifications.get_uid_by_name(\"default_py3.6\") \nsoftware_spec_uid", "execution_count": 26, "outputs": [{"output_type": "execute_result", "execution_count": 26, "data": {"text/plain": "'0062b8c9-8b7d-44a0-a9b9-46c416adcbd9'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "model_details = client.repository.store_model(model='parkinsonsmodel.tgz',meta_props={\nclient.repository.ModelMetaNames.NAME: \"parkinson\", \nclient.repository.ModelMetaNames.TYPE: \"default_py3.6\", \nclient.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid})\nmodel_id = client.repository.get_model_uid(model_details)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# "}, {"metadata": {}, "cell_type": "markdown", "source": "#### Using wave images"}, {"metadata": {}, "cell_type": "markdown", "source": "### Defining the path for wave training data and testing data"}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "5hv2fgLED8vO", "outputId": "1c1a4ada-99c6-43de-ee34-c6f8b7c81887"}, "cell_type": "code", "source": "path_training_data = r\"dataset/wave/training\"\npath_testing_data = r\"dataset/wave/testing\"", "execution_count": 58, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Loading the training and testing data"}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "rxwdUgSrHVnl", "outputId": "8a569025-1f4d-41eb-8199-162a823517f0"}, "cell_type": "code", "source": "(x_train, y_train) = load_split(path_training_data)\n(x_test, y_test) = load_split(path_testing_data)", "execution_count": 61, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Label Encoding"}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "label_encoder = LabelEncoder()\ny_train = label_encoder.fit_transform(y_train)\ny_test = label_encoder.transform(y_test)\nprint(x_train.shape, y_train.shape)\n# 0:healthy,1:Parkinson", "execution_count": 62, "outputs": [{"output_type": "stream", "text": "(72, 54756) (72,)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Building the model"}, {"metadata": {}, "cell_type": "markdown", "source": "### Training the model"}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "model = RandomForestClassifier(n_estimators=100)\nmodel.fit(x_train, y_train)", "execution_count": 63, "outputs": [{"output_type": "execute_result", "execution_count": 63, "data": {"text/plain": "RandomForestClassifier()"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Testing the model"}, {"metadata": {}, "cell_type": "code", "source": "testingPaths = list(paths.list_images(path_testing_data))\nidxs = np.arange(0, len(testingPaths))\nidxs = np.random.choice(idxs, size=(25,), replace=False) \nimages = []", "execution_count": 64, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "for i in idxs:\n    # loading the testing image, clone it, and resize it \n    image = cv2.imread(testingPaths[i]) \n    output = image. copy() \n    output = cv2. resize(output, (128, 128))\n    \n    # pre-processing the image \n    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n    image = cv2.resize(image, (200, 200))\n    image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU) [1]\n    \n    # quantify the image and make predictions based on the extracted \n    # features using the last trained Random Forest \n    features = quantify_image(image) \n    preds = model.predict([features])\n\n    label = label_encoder.inverse_transform(preds)[0]\n\n    # draw the colored class label on the output image and add it to the set of output images \n    if label == \"healthy\":\n        color = (0, 255, 0)  \n    else:\n        color = (0, 0, 255) \n    cv2.putText(output, label, (3, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2) \n    images.append(output)", "execution_count": 65, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Evaluating the model"}, {"metadata": {}, "cell_type": "code", "source": "predictions = model.predict(x_test)    # predictions on the testing data \n\ncm = confusion_matrix(y_test, predictions).flatten ()    # computing the confusion matrix\nprint(cm) \n(tn, fp, fn, tp) = cm \n\naccuracy = (tp + tn) / float(cm.sum())     # computing the accuracy\nprint(accuracy)", "execution_count": 66, "outputs": [{"output_type": "stream", "text": "[10  5  5 10]\n0.6666666666666666\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Saving the model"}, {"metadata": {}, "cell_type": "code", "source": "pickle.dump(model,open('parkinson_w.pkl', 'wb'))", "execution_count": 67, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "!tar -zcvf parkinsons-detection-model_s.tgz parkinson_w.pkl", "execution_count": 68, "outputs": [{"output_type": "stream", "text": "parkinson_w.pkl\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "ls", "execution_count": 69, "outputs": [{"output_type": "stream", "text": "\u001b[0m\u001b[01;34mdataset\u001b[0m/       parkinsons-detection-model_s.tgz  parkinson_w.pkl\r\nparkinson.pkl  parkinsonsmodel.tgz\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "# "}], "metadata": {"colab": {"collapsed_sections": [], "provenance": []}, "kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}